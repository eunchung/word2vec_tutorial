{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 적당한 문장을 남기고 필터링하여 품사 태깅을 수행합니다. => comment_corpus.tag\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "from konlpy.utils import pprint\n",
    "import os\n",
    "from sgmllib import SGMLParser, SGMLParseError\n",
    "import sys\n",
    "\n",
    "class TextExtracter(SGMLParser):\n",
    "    \"\"\"\n",
    "    HTML 문서에서 태그와 엔티티를 제거하고 텍스트만 추출하는 클래스\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.text = []\n",
    "        SGMLParser.__init__(self)\n",
    "    def handle_data(self, data):\n",
    "        self.text.append(data)\n",
    "    def getvalue(self):\n",
    "        return ''.join(self.text)\n",
    "    @classmethod\n",
    "    def get_text(cls, html):\n",
    "        txt_ext = TextExtracter()\n",
    "        txt_ext.feed(html)\n",
    "        return txt_ext.getvalue()\n",
    "\n",
    "def ascii_count(text):\n",
    "    \"\"\"\n",
    "    문자열에서 ASCII 영역 문자의 갯수를 세는 함수\n",
    "    @param  text  문자열\n",
    "    @return       ASCII 문자 갯수\n",
    "    \"\"\"\n",
    "    return sum([1 for char in text if ord(char) & 0x80 == 0])\n",
    "\n",
    "mecab = Mecab('%s/usr/mecab-ko/lib/mecab/dic/mecab-ko-dic' % os.environ['HOME'])\n",
    "\n",
    "with open('comment_corpus.tag', 'w') as fout:\n",
    "    for line_num, line in enumerate(open('comment_corpus.txt'), start=1):    # 댓글 코퍼스를 읽어들입니다.\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            line = TextExtracter.get_text(line)    # 태그를 제거하고 텍스트만 남깁니다.\n",
    "        except SGMLParseError:\n",
    "            pass\n",
    "        if ascii_count(line) > (len(line) / 5):    # ASCII 문자의 갯수가 전체의 1/5을 넘는 댓글은 제거합니다.\n",
    "            continue\n",
    "        words = line.split()\n",
    "        if len(words) < 5:    # 단어의 갯수가 5개 미만인 댓글은 제거합니다.\n",
    "            continue\n",
    "        raw = ' '.join(words)\n",
    "        tagged = ['%s/%s' % (morph.encode('UTF-8'), tag.encode('UTF-8'))    # '형태소/태그' 형태로 저장합니다.\n",
    "                  for morph, tag in mecab.pos(unicode(raw, 'UTF-8'))]\n",
    "        print >> fout, ' '.join(tagged)\n",
    "\n",
    "!head -n5 comment_corpus.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### 200만 문장을 샘플링하여 gensim을 이용해 doc2vec을 학습합니다. => comment_corpus_2m.d2v\n",
    "\n",
    "!shuf -n 2000000 comment_corpus.tag > comment_corpus.tag.2m\n",
    "\n",
    "import gensim\n",
    "import sys\n",
    "\n",
    "path = 'comment_corpus_2m.tag'\n",
    "def documents():\n",
    "    \"\"\"\n",
    "    전체 문서를 읽어들여 문장(LabeledSentence 객체)을 하나씩 반환하는 제너레이터\n",
    "    \"\"\"\n",
    "    print >> sys.stderr, path\n",
    "    for line_num, line in enumerate(open(path), start=1):\n",
    "        if line_num % 1000000 == 0:\n",
    "            print >> sys.stderr, '    %dm-th line' % (line_num / 1000000)\n",
    "        if not line:\n",
    "            continue\n",
    "        words = [unicode(word, 'UTF-8') for word in line.split()]    # 단어는 모두 유니코드로 저장해야 합니다.\n",
    "        yield gensim.models.doc2vec.LabeledSentence(words=words, tags=[unicode(line_num),])\n",
    "\n",
    "d2v_model = gensim.models.Doc2Vec(size=300, alpha=0.025, min_alpha=0.025, workers=20)\n",
    "d2v_model.build_vocab(documents())    # vocabulary를 먼저 생성합니다.\n",
    "for epoch in range(10):    # 10회 반복하여 학습을 진행합니다.\n",
    "    print >> sys.stderr, '[%d] epoch:' % epoch,\n",
    "    d2v_model.train(documents())\n",
    "    d2v_model.alpha -= 0.002    # alpha 값을 줄여 learning rate를 서서히 줄입니다.\n",
    "    d2v_model.min_alpha = d2v_model.alpha    # epoch 내에서는 learning rate를 decay 없이 고정합니다.\n",
    "d2v_model.save(path.replace('.tag', '.d2v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
